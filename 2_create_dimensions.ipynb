{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fac4b87-b835-4472-8df6-7c5444846d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd46f557-c4b3-4bb3-9ab3-38cd6f2904d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from https://github.com/professorholowczak/Data_Warehousing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9f29716-09db-4240-9eb7-35861fc496fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp_project = 'cis4400-381214' # replace to your own project id\n",
    "bq_dataset = '311_complaints_dataset' # replace to your own dataset name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dfe1f91-cdc3-4f9b-b3a8-6845878a8b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data_file(logging, file_name, df):\n",
    "    logging.info(f'Reading source data file: {file_name}')\n",
    "    try:\n",
    "        df = pd.read_csv(file_name, low_memory=False)\n",
    "        df = df.rename(columns=str.lower)\n",
    "        logging.info(f'Read {len(df)} records from source data file: {file_name}')\n",
    "        return df\n",
    "    except:\n",
    "        logging.error(f'Failed to read file: {file_name}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fd5f676-3372-4054-9cc7-9869774e5ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(logging, columns, df):\n",
    "    logging.info('Transforming dataframe.')\n",
    "    column_list = columns\n",
    "    df = df[column_list]\n",
    "    df = df.drop_duplicates()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "945a2a03-36fe-4130-9e2c-4672d2214bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigquery_client(logging):\n",
    "    try:\n",
    "        bqclient = bigquery.Client.from_service_account_json('keys/new-cis4400-381214-f4f2229d6853.json') # replace with your own SA keys\n",
    "        logging.info('Created BigQuery Client: %s', bqclient)\n",
    "        return bqclient\n",
    "    except Exception as err:\n",
    "        logging.error('Failed to create BigQuery Client.', err)\n",
    "    return bqclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0742b3fc-34af-4c42-a482-9203242ea021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_bigquery_table(logging, bqclient, table_path, write_disposition, df):\n",
    "    try:\n",
    "        logging.info('Creating BigQuery Job configuration with write_disposition=%s', write_disposition)\n",
    "        job_config = bigquery.LoadJobConfig(write_disposition=write_disposition)\n",
    "        logging.info('Submitting the BigQuery job')\n",
    "        job = bqclient.load_table_from_dataframe(df, table_path, job_config=job_config)  \n",
    "        logging.info('Job  results: %s',job.result())\n",
    "    except Exception as err:\n",
    "        logging.error('Failed to load BigQuery Table. %s', err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "192573a0-1a96-41a6-a8db-0b455c65a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigquery_table_exists(bqclient, table_path):  \n",
    "    try:\n",
    "        bqclient.get_table(table_path)\n",
    "        return True\n",
    "    except NotFound:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1a282c2-66af-4fb1-b8ed-77417d03557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_bigquery_table(logging, table_path, bqclient, surrogate_key): \n",
    "    bq_df = pd.DataFrame\n",
    "    sql_query = 'SELECT * EXCEPT ( update_timestamp, ' + surrogate_key + ') FROM `' + table_path + '`'\n",
    "    logging.info('Running query: %s', sql_query)\n",
    "    try:\n",
    "        bq_df = bqclient.query(sql_query).to_dataframe()\n",
    "    except Exception as err:\n",
    "        logging.info('Error querying the table. %s', err)\n",
    "    return bq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed348482-3b38-4062-8c94-1dbac92f235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_surrogate_key(df, dimension_name, offset=1):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.insert(0, dimension_name + '_dim_id', df.index + offset)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6caf26a-62b7-451a-bd73-286739c471c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_update_date(df, current_date):\n",
    "    df['update_date'] = pd.to_datetime(current_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85021ca6-58a2-42d5-8548-e2b1b5d3f3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_update_timestamp(df):\n",
    "    df['update_timestamp'] = pd.to_datetime('now', utc=True).replace(microsecond=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91aae451-4b88-4260-beb7-93707fa439ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_new_table(logging, bqclient, dimension_table_path, dimension_name, df):\n",
    "    logging.info('Target dimension table %s does not exit', dimension_table_path)\n",
    "    df = add_surrogate_key(df, dimension_name, 1)\n",
    "    df = add_update_timestamp(df)\n",
    "    upload_bigquery_table(logging, bqclient, dimension_table_path, 'WRITE_TRUNCATE', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "786f24ad-7bd9-4c59-8941-85375894252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_existing_table(logging, bqclient, dimension_table_path, dimension_name, surrogate_key, df):\n",
    "    bq_df = pd.DataFrame\n",
    "    logging.info('Target dimension table %s exits. Checking for differences.', dimension_table_path)\n",
    "    bq_df = query_bigquery_table(logging, dimension_table_path, bqclient, surrogate_key)\n",
    "    # new_records_df = pd.concat([df, bq_df]).drop_duplicates(keep=False)\n",
    "    new_records_df = df[~df.apply(tuple,1).isin(bq_df.apply(tuple,1))]\n",
    "    logging.info('Found %d new records.', new_records_df.shape[0])\n",
    "    if new_records_df.shape[0] > 0:\n",
    "        new_surrogate_key_value = bq_df.shape[0] + 1\n",
    "        new_records_df = add_surrogate_key(new_records_df, dimension_name, new_surrogate_key_value)\n",
    "        new_records_df = add_update_timestamp(new_records_df)\n",
    "        upload_bigquery_table(logging, bqclient, dimension_table_path, 'WRITE_APPEND', new_records_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51e77b3c-ee2d-4f58-b6bf-02380816af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary and list for loops\n",
    "dim_dict = {\n",
    "    'agency':['agency', 'agency_name'],\n",
    "    'location':['incident_zip', 'intersection_street_1', 'intersection_street_2', 'borough', 'city'],\n",
    "    'complaints_status':['status'],\n",
    "    'complaint_type':['descriptor'],\n",
    "    'date':['created_date', 'closed_date']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1b4d2cd-9725-44a9-88d7-b60422d891c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1256/2568242343.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['update_timestamp'] = pd.to_datetime('now', utc=True).replace(microsecond=0)\n",
      "/tmp/ipykernel_1256/2568242343.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['update_timestamp'] = pd.to_datetime('now', utc=True).replace(microsecond=0)\n",
      "/tmp/ipykernel_1256/2568242343.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['update_timestamp'] = pd.to_datetime('now', utc=True).replace(microsecond=0)\n",
      "/tmp/ipykernel_1256/2568242343.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['update_timestamp'] = pd.to_datetime('now', utc=True).replace(microsecond=0)\n",
      "/tmp/ipykernel_1256/2568242343.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['update_timestamp'] = pd.to_datetime('now', utc=True).replace(microsecond=0)\n",
      "/tmp/ipykernel_1256/2568242343.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['update_timestamp'] = pd.to_datetime('now', utc=True).replace(microsecond=0)\n",
      "/tmp/ipykernel_1256/2568242343.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['update_timestamp'] = pd.to_datetime('now', utc=True).replace(microsecond=0)\n",
      "/tmp/ipykernel_1256/2568242343.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['update_timestamp'] = pd.to_datetime('now', utc=True).replace(microsecond=0)\n",
      "/tmp/ipykernel_1256/2568242343.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['update_timestamp'] = pd.to_datetime('now', utc=True).replace(microsecond=0)\n"
     ]
    }
   ],
   "source": [
    "for key, value in dim_dict.items():\n",
    "    dimension_name = key\n",
    "    surrogate_key = f'{dimension_name}_dim_id'\n",
    "    business_key = f'{dimension_name}_id'\n",
    "\n",
    "    table_name = f'{dimension_name}_dimension'\n",
    "    dimension_table_path = f'{gcp_project}.{bq_dataset}.{table_name}'\n",
    "    \n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "\n",
    "    current_date = datetime.today().strftime('%Y%m%d')\n",
    "    log_filename = '_'.join(['etl', dimension_name, current_date]) + '.log'\n",
    "    logging.basicConfig(filename=log_filename, encoding='utf-8', format='%(asctime)s %(message)s', level=logging.DEBUG)\n",
    "    logging.info('=========================================================================')\n",
    "    logging.info(f'Starting ETL Run for dimension {dimension_name} on date {current_date}')\n",
    "    \n",
    "    columns = value\n",
    "    for year in range(2019, 2024):\n",
    "        if __name__ == '__main__':\n",
    "            if dimension_name == 'location':\n",
    "                df = pd.DataFrame\n",
    "                df = load_csv_data_file(logging, f'data/311_traffic_signal_complaints_{year}.csv', df)\n",
    "                df = transform_data(logging, columns, df)\n",
    "                df['state'] = 'NY'\n",
    "                bqclient = create_bigquery_client(logging)\n",
    "                target_table_exists = bigquery_table_exists(bqclient, dimension_table_path)\n",
    "                if not target_table_exists:\n",
    "                    build_new_table(logging, bqclient, dimension_table_path, dimension_name, df)\n",
    "                if target_table_exists:\n",
    "                    insert_existing_table(logging, bqclient, dimension_table_path, dimension_name, surrogate_key, df)\n",
    "                logging.shutdown()\n",
    "\n",
    "            else:\n",
    "                df = pd.DataFrame\n",
    "                df = load_csv_data_file(logging, f'data/311_traffic_signal_complaints_{year}.csv', df)\n",
    "                df = transform_data(logging, columns, df)\n",
    "                bqclient = create_bigquery_client(logging)\n",
    "                target_table_exists = bigquery_table_exists(bqclient, dimension_table_path)\n",
    "                if not target_table_exists:\n",
    "                    build_new_table(logging, bqclient, dimension_table_path, dimension_name, df)\n",
    "                if target_table_exists:\n",
    "                    insert_existing_table(logging, bqclient, dimension_table_path, dimension_name, surrogate_key, df)\n",
    "                logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ec5a19-43c1-4e13-8c87-d1f90441655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2019 = pd.read_csv('data/311_traffic_signal_complaints_2019.csv')\n",
    "df2019 = df2019['status']\n",
    "df2019.drop_duplicates(inplace=True)\n",
    "\n",
    "df2020 = pd.read_csv('data/311_traffic_signal_complaints_2020.csv')\n",
    "df2020 = df2020['status']\n",
    "df2020.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a5f14c7-0e7b-4629-897c-519ed1824cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Closed\n",
       "3770        Open\n",
       "3808    Assigned\n",
       "Name: status, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "325f5b0b-5c11-43ee-93d3-fafdc36d5c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Closed\n",
       "6410    Pending\n",
       "Name: status, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "016948be-93e6-4e82-8f75-5712164960db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Closed\n",
       "3770        Open\n",
       "3808    Assigned\n",
       "0         Closed\n",
       "6410     Pending\n",
       "Name: status, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df2019, df2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20a247f4-f06e-41f4-9ca9-880db5bc8509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3770        Open\n",
       "3808    Assigned\n",
       "6410     Pending\n",
       "Name: status, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_records_df = pd.concat([df2019, df2020]).drop_duplicates(keep=False)\n",
    "new_records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d117e26b-b465-4eac-a825-4a6e45d2a9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6410    Pending\n",
       "Name: status, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2020[~df2020.apply(tuple,1).isin(df2019.apply(tuple,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853fdaed-e9b8-4aea-9eaf-f9ff774c3437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a0ae724-0502-43d8-b15f-c0c64ccf209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1256/2942858748.py:1: DtypeWarning: Columns (26,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2019_1 = pd.read_csv('data/311_traffic_signal_complaints_2019.csv')\n"
     ]
    }
   ],
   "source": [
    "df2019_1 = pd.read_csv('data/311_traffic_signal_complaints_2019.csv')\n",
    "df2019_1 = df2019_1[['incident_zip', 'intersection_street_1', 'intersection_street_2', 'borough', 'city']]\n",
    "df2019_1.drop_duplicates(inplace=True)\n",
    "\n",
    "df2020_1 = pd.read_csv('data/311_traffic_signal_complaints_2020.csv')\n",
    "df2020_1 = df2020_1[['incident_zip', 'intersection_street_1', 'intersection_street_2', 'borough', 'city']]\n",
    "df2020_1.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b98b6da-6a14-46b9-9469-cbcb3af4149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = df2020_1[~df2020_1.apply(tuple,1).isin(df2019_1.apply(tuple,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db98b9f4-3933-41fe-bb0c-37042009f950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48eb29e-c56b-4f11-aa12-4d21b755871c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nyc-311-dw]",
   "language": "python",
   "name": "conda-env-nyc-311-dw-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
